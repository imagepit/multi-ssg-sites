---
title: "【LLM】タスク分割とTemperature調整で出力を改善する"
source: "https://zenn.dev/fivot/articles/fec94dcb2fb6a7"
author:
  - "[[Zenn]]"
published: 2025-08-06
created: 2025-10-10
description:
tags:
  - "clippings"
---

記事の要約を、指定の箇所に追加します。

:::note
## 記事要約
LLMの出力安定性を向上させるには、プロンプトの調整だけでなく、「タスクの分割」と「temperatureの使い分け」が重要です。LLMが複雑なタスクを一度に処理しようとすると、複数の認知プロセスが同時に発生し、出力が不安定になることがあります。

この問題を解決するため、記事では以下の手法を推奨しています。
1.  **タスクを分割する**: 複雑なタスク（例：メール作成）を、人間が問題を解決する際のように「要件整理フェーズ」と「執筆フェーズ」といった、より単純な段階に分けます。
2.  **temperatureを使い分ける**: 各段階の特性に合わせてtemperatureを設定します。
    *   **要件整理など、客観的で一貫性のある出力が求められるタスク**には、低いtemperature（例: 0.1）を設定し、安定した結果を得ます。
    *   **文章生成など、適度な表現力が求められるタスク**には、中程度のtemperature（例: 0.5）を設定し、適切な表現の幅を持たせます。

この手法は、認知負荷の分散、各段階でのtemperatureの最適化、エラー特定の容易化、段階的な改善といった利点をもたらし、LLMの出力精度向上に効果的です。
:::

## はじめに
<!-- ... existing content ... -->
</smtcmp_block>

## はじめに

LLMを使ったアプリケーションを開発していると、「なんだか出力がブレる」「もう少し安定した結果が欲しい」と感じることがあります。そんな時、プロンプトを練り直すことに注力しがちですが、根本的な解決策を見過ごしていることがたまにあります。

それが「タスクの分割」と「temperatureの使い分け」です。

## LLMの出力が不安定になる理由

まず、なぜLLMの出力が不安定になるのかを理解する必要があります。

LLMは基本的に「次の単語を予測する」システムです。入力されたテキストに対して、最も適切だと判断される次の単語を確率的に選択します。この時、temperatureパラメータが重要な役割を果たします。

temperatureが高いと、予測の幅が広がり、創造的だが予測しにくい出力になります。逆に低いと、より確実性の高い、安定した出力になります。

複雑なタスクを一度に処理させようとすると、LLMは「分析」「評価」「文章生成」といった異なる認知プロセスを同時に実行しなければなりません。これが出力の不安定さを生む要因の一つです。

## メールを例に

重要なメールを書くタスクがあるとします。  
自分がもっともシンプルに実装なら、以下のようなプロンプトを書くと思います。

```dart
ver prompt = '''
以下の情報をもとに、ビジネスメール作成してください：
- 送信先: ${recipient}
- 内容: ${content}

メール作成条件:
- 件名も含めて作成
- 相手との関係性を考慮
- 簡潔で分かりやすく
- 適切な敬語を使用
'''
```

モデルが十分に高性能であれば、上記のプロンプトでも十分精度の高い出力が得られるかもしれません。しかし、低性能なモデルを使用している場合や、目的の複雑さによっては精度が上がらないこともあるでしょう。

## タスクを分割する

人間が複雑な問題を解決する時を考えてみましょう。頭の中で以下のような段階を踏むはずです。

1. **整理フェーズ**: 伝えたい内容や目的を明確にして、要点を整理する
2. **執筆フェーズ**: 相手との関係性や状況に応じて、適切なトーンで文章を作成する

この2つは明らかに異なる思考プロセスです。前者は論理的で客観的、後者は相手への配慮や表現力が重要になります。

LLMも同様に、この2つのプロセスを分離してやることで、それぞれに最適化された処理ができるようになります。

## 実装の例

具体的な実装だと、こんなイメージ。

```dart
// 第一段階: 要件整理専用モデル（temperature: 0.1）
ver structureModel = generateModel(
  temperature: 0.1,  // 低い値で安定した構造化
  maxTokens: 150     // 簡潔な要点整理
);

// 第二段階: メール作成専用モデル（temperature: 0.5）
ver compositionModel = generateModel(
  temperature: 0.5,  // 適度な表現力
  maxTokens: 300     // 充分な文章量
);
```

### 第一段階: 要件の構造化

```dart
ver structurePrompt = '''
以下の情報から、メールの要件を整理してください：
- 送信先: ${recipient}
- 内容: ${content}

出力形式:
目的: []
背景: []
期限: []
重要ポイント: [箇条書き]
トーン: [フォーマル/カジュアル/丁寧]
''';

ver structureResult = await structureModel.generate(structurePrompt);
```

ここでのポイントは、temperature 0.1という低い値を使っていることです。要件整理は客観的で一貫性のある結果が求められるため、ランダム性を抑えた設定にしています。

### 第二段階: メール文章の作成

第一段階の出力を、二段階目のプロンプトに含めます。

```dart
ver compositionPrompt = '''
以下の整理された要件を元に、適切なビジネスメールを作成してください:
${structureResult}

メール作成条件:
- 件名も含めて作成
- 相手との関係性を考慮
- 簡潔で分かりやすく
- 適切な敬語を使用
''';

ver emailDraft = await compositionModel.generate(compositionPrompt);
```

文章生成では temperature 0.5 を使用しています。これにより、構造化された要件という安定した入力を元に、適度な表現の幅を持ったメールが生成されます。

## なぜこの手法が効果的か

### 1\. 認知負荷の分散

複雑なタスクを一度に処理させると、LLMは複数の異なる処理を同時に行う必要があります。タスクを分割することで、それぞれのステップに集中できるようになります。

### 2\. temperatureの最適化

各段階で求められる出力特性が異なるため、それぞれに最適なtemperatureを設定できます。要件整理では一貫性、文章作成では表現力を重視できます。

### 3\. エラーの特定とデバッグ

問題が発生した時、どの段階で問題が起きているのかを特定しやすくなります。要件の理解が間違っているのか、文章表現が適切でないのかが明確になります。

### 4\. 段階的な改善

各段階を独立して最適化できるため、システム全体の精度向上が図りやすくなります。

## まとめ

LLMの出力精度を向上させるために、プロンプト調整に注力することは確かに重要です。しかし、それと同じくらい「どのようにタスクを分割するか」「各段階でどのtemperatureを使うか」という設計も（当然ですが）大切になります。

次回LLMを使った機能を実装する時は、一度立ち止まって「このタスクは本当に一つの処理で済むだろうか？」と考えてみるようにしたいなと思いました。

1

### Discussion

![](https://static.zenn.studio/images/drawing/discussion.png)

ログインするとコメントできます